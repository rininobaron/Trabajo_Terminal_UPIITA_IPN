{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anexo S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desplegando modelo EfficientNet en IBM Watson\n",
    "\n",
    "#### Elaborado por: Ricardo Niño de Rivera Barrón\n",
    "\n",
    "#### Ingeniería Biónica\n",
    "\n",
    "#### Trabajo Terminal II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta libreta interactiva realizada en IBM Watson se describe el proceso para desplegar un modelo EfficientNet en la nube utilizando las herramientas que proporciona gratuitamente IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Importando biblioteca EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando todos los métodos\n",
    "# from efficientnet.keras import EfficientNetB7\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando el ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente es necesario crear una instancia gratuita en Watson para utilizar el servicio específico de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conectando a Watson Machine Learning\n",
    "\n",
    "Para comunicarnos con la instancia creada necesitamos dos datos, \"Api Key\" y la ubicación geográfica de la instancia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "location = 'us-south'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": api_key,\n",
    "    \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando la biblioteca para manipular recursos en IBM Watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-04 02:02:55,297 - tensorflow - WARNING - Large dropout rate: 0.5125 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "2020-12-04 02:02:55,516 - tensorflow - WARNING - Large dropout rate: 0.525 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "2020-12-04 02:02:55,750 - tensorflow - WARNING - Large dropout rate: 0.5375 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "2020-12-04 02:02:55,983 - tensorflow - WARNING - Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "2020-12-04 02:02:56,233 - tensorflow - WARNING - Large dropout rate: 0.5625 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "2020-12-04 02:09:10,736 - ibm_watson_machine_learning.wml_client_error - WARNING - Deployment creation failed for deployment id: b47972d6-3193-43c9-be6b-dc5cf853b159. Errors: [{'code': 'invalid_model_archive', 'message': 'Keras model load failed with error: Unknown layer: FixedDropout', 'target': {'type': 'none', 'name': 'none'}, 'more_info': 'none'}]\n",
      "2020-12-04 02:43:02,835 - ibm_watson_machine_learning.wml_client_error - WARNING - Failure during scoring. (POST https://us-south.ml.cloud.ibm.com/ml/v4/deployments/ceabd03b-9278-402f-981d-7ea2a5d5f7e1/predictions?version=2020-08-01)\n",
      "Status code: 400, body: {\"trace\": \"6b110b82fa9f357ebd1b55934ceb7148\", \"errors\": [{\"code\": \"invalid_input_data\", \"message\": \"Input efficientnet-b7_input expected input data with shape: [None, 128, 128, 3] but received input data with shape: [1]. Retry the prediction with input data with correct shape\"}], \"status_code\": 400}\n",
      "\n",
      "2020-12-04 02:44:37,070 - ibm_watson_machine_learning.wml_client_error - WARNING - Failure during scoring. (POST https://us-south.ml.cloud.ibm.com/ml/v4/deployments/ceabd03b-9278-402f-981d-7ea2a5d5f7e1/predictions?version=2020-08-01)\n",
      "Status code: 400, body: {\"trace\": \"e666c2f26b28b466f184277caa0fc16d\", \"errors\": [{\"code\": \"invalid_input_data\", \"message\": \"Input efficientnet-b7_input expected input data with shape: [None, 128, 128, 3] but received input data with shape: [1, 1, 128, 128, 3]. Retry the prediction with input data with correct shape\"}], \"status_code\": 400}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con espacios\n",
    "\n",
    "Posteriormente se debe establecer un \"espacio\" de trabajo en en en el servicio de almacenamiento de objetos de IBM Cloud.\n",
    "\n",
    "Para realizar esta tarea es posible realizarla en esta libreta o directamente en la plataforma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_id = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlistando todos los espacios existentes en la instancia creada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ----------------  ------------------------\n",
      "ID                                    NAME              CREATED\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  EfficientNet_TT2  2020-12-03T14:58:40.571Z\n",
      "------------------------------------  ----------------  ------------------------\n"
     ]
    }
   ],
   "source": [
    "client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora establecemos el espacio creado como espacio por default para desplegar el modelo propuesto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resources': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.get_job_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargando ejemplo de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mega.py\n",
      "  Downloading mega.py-1.0.8-py2.py3-none-any.whl (19 kB)\n",
      "Collecting pathlib==1.0.1\n",
      "  Downloading pathlib-1.0.1.tar.gz (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 7.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tenacity<6.0.0,>=5.1.5\n",
      "  Downloading tenacity-5.1.5-py2.py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: requests>=0.10 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from mega.py) (2.24.0)\n",
      "Collecting pycryptodome<4.0.0,>=3.9.6\n",
      "  Downloading pycryptodome-3.9.9-cp37-cp37m-manylinux1_x86_64.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 20.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tenacity<6.0.0,>=5.1.5->mega.py) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests>=0.10->mega.py) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests>=0.10->mega.py) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests>=0.10->mega.py) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests>=0.10->mega.py) (1.25.9)\n",
      "Building wheels for collected packages: pathlib\n",
      "  Building wheel for pathlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathlib: filename=pathlib-1.0.1-py3-none-any.whl size=14346 sha256=d1816d7868fc64c2fc0c203e9f7c2ed34ee943448337fdba354598172f9ad9da\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/6e/96/b8/10037fe231e23970bac58361d7c93571ab983a7bbc55e68550\n",
      "Successfully built pathlib\n",
      "Installing collected packages: pathlib, tenacity, pycryptodome, mega.py\n",
      "Successfully installed mega.py-1.0.8 pathlib-1.0.1 pycryptodome-3.9.9 tenacity-5.1.5\n"
     ]
    }
   ],
   "source": [
    "# Instalando biblioteca mega.py\n",
    "!pip install mega.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mega import Mega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega = Mega()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicamos sesión en MEGA con cuenta temporal y anónima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in en la cuenta de MEGA con cuenta temporal anónima\n",
    "m = mega.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('T0032.1.1.D.2016-10-29.16.npy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargando el archivo de prueba T0032.1.1.D.2016-10-29.16.npy\n",
    "m.download_url('https://mega.nz/file/URwlCCpC#It8L-P9xJexCtwgFY2q1NbXkEH8A9aVg9JWZfedLLjw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T0032.1.1.D.2016-10-29.16.npy\r\n"
     ]
    }
   ],
   "source": [
    "# Mostrando archivos en el directorio de trabajo del entorno\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wsuser/work\r\n"
     ]
    }
   ],
   "source": [
    "# Imprimiendo el directorio de trabajo\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leyendo archivo con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prueba = np.load('T0032.1.1.D.2016-10-29.16.npy')\n",
    "X_prueba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acondicionando imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importando bibliotecas auxiliares\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo función get_img para leer los archivos numpy y ajustarlos a nuevo tamaño.\n",
    "# La imagen que retorna la función también es normalizada sobre los valor máximo del pixel (255)\n",
    "def get_img(imagen, size=128):\n",
    "    \n",
    "    img = np.expand_dims(imagen, axis=2)\n",
    "    \n",
    "    return tf.image.resize(img, [size,size], antialias=True)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 128, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prueba = get_img(X_prueba)\n",
    "X_prueba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_prueba_128\n",
    "\n",
    "X_prueba_128 = np.zeros((1, 128, 128,3))\n",
    "\n",
    "# Almacenamos la imagen obtenida en cada canal\n",
    "X_prueba_128[0,:,:,0] = X_prueba[:,:,0]\n",
    "X_prueba_128[0,:,:,1] = X_prueba[:,:,0]\n",
    "X_prueba_128[0,:,:,2] = X_prueba[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T0032.1.1.D.2016-10-29.16.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargando los archivos del modelo EfficientNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargando archivos desde Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-04 02:02:03--  https://www.kaggleusercontent.com/kf/48361538/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..06envnQufMII0qsVqfsHRA.7zF6cLYBvn-y2o6LCup5VFIuTqQJTyoP8ahEkiUOe88VLrnCcuKRGnJl5jvA8BIBQoLGo2YSh_Pnv8qGvaiss7p0The2f3wfN286A-3riDBIDMRbzvNY_9XpeuigFExcgm199G69Z0qegjGEP_QknHKrDfZvb3ln5XyLBdrkvL2fvpfOPLFviItY1SR6qnCuUDpQy3qNTVoKFlHBf2ajwoo8Ss_Aaev2CRRb0tDpKPJq52Cbh5J5I4lwa9xvHrnDH5gqZW3dgz3PIx-E7kr6SrEhqEcNyCVTgGJXcpI8TYVDo7HZ48jZxJDuNLFf64AJkEmux9pgJURi0UBKiWA2mUuQ-ykWHcYErtkflAZjurB-om42CxTmBMOUZh1k97G6-Cv-7aWhE3PrOC77teE5OCPXEfeHpWicEQ4vCV3ow_RMwM-UxlIx4nfbkCmi9x8Qg7lKNtDv1HZ3-rsrofG0E9YvaKBhoQMbQpoJrGY6UHZ8iOdngnHUF1ogImA8Fk4kGceXRRFf0OWnEwgtH7bKz2ohwtsZ2T6QJHdgxWO_kfox9mUOr3wx-8ijD_hkvu0CqNLvZMoZF1awIycTZ6A0FCxwPgZj3Kb7ZD0uPRU4Cojpac22R92Vxq4U2IbHv7lg.g8Py8ocuWzzMZfiOCkYN0g/EFNB7_weights.h5\n",
      "Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n",
      "Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2984398720 (2.8G) [application/octet-stream]\n",
      "Saving to: ‘EFNB7_weights.h5’\n",
      "\n",
      "EFNB7_weights.h5    100%[===================>]   2.78G   104MB/s    in 29s     \n",
      "\n",
      "2020-12-04 02:02:32 (97.6 MB/s) - ‘EFNB7_weights.h5’ saved [2984398720/2984398720]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descargando archivo con modelo EficienNetB7 EFNB7_weights.h5\n",
    "!wget https://www.kaggleusercontent.com/kf/48361538/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..06envnQufMII0qsVqfsHRA.7zF6cLYBvn-y2o6LCup5VFIuTqQJTyoP8ahEkiUOe88VLrnCcuKRGnJl5jvA8BIBQoLGo2YSh_Pnv8qGvaiss7p0The2f3wfN286A-3riDBIDMRbzvNY_9XpeuigFExcgm199G69Z0qegjGEP_QknHKrDfZvb3ln5XyLBdrkvL2fvpfOPLFviItY1SR6qnCuUDpQy3qNTVoKFlHBf2ajwoo8Ss_Aaev2CRRb0tDpKPJq52Cbh5J5I4lwa9xvHrnDH5gqZW3dgz3PIx-E7kr6SrEhqEcNyCVTgGJXcpI8TYVDo7HZ48jZxJDuNLFf64AJkEmux9pgJURi0UBKiWA2mUuQ-ykWHcYErtkflAZjurB-om42CxTmBMOUZh1k97G6-Cv-7aWhE3PrOC77teE5OCPXEfeHpWicEQ4vCV3ow_RMwM-UxlIx4nfbkCmi9x8Qg7lKNtDv1HZ3-rsrofG0E9YvaKBhoQMbQpoJrGY6UHZ8iOdngnHUF1ogImA8Fk4kGceXRRFf0OWnEwgtH7bKz2ohwtsZ2T6QJHdgxWO_kfox9mUOr3wx-8ijD_hkvu0CqNLvZMoZF1awIycTZ6A0FCxwPgZj3Kb7ZD0uPRU4Cojpac22R92Vxq4U2IbHv7lg.g8Py8ocuWzzMZfiOCkYN0g/EFNB7_weights.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFNB7_weights.h5  T0032.1.1.D.2016-10-29.16.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo EfficientNet en https://github.com/qubvel/efficientnet/blob/master/efficientnet/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando bibliotecas y métodos de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _obtain_input_shape(input_shape,\n",
    "                        default_size,\n",
    "                        min_size,\n",
    "                        data_format,\n",
    "                        require_flatten,\n",
    "                        weights=None):\n",
    "    \"\"\"Internal utility to compute/validate a model's input shape.\n",
    "    # Arguments\n",
    "        input_shape: Either None (will return the default network input shape),\n",
    "            or a user-provided shape to be validated.\n",
    "        default_size: Default input width/height for the model.\n",
    "        min_size: Minimum input width/height accepted by the model.\n",
    "        data_format: Image data format to use.\n",
    "        require_flatten: Whether the model is expected to\n",
    "            be linked to a classifier via a Flatten layer.\n",
    "        weights: One of `None` (random initialization)\n",
    "            or 'imagenet' (pre-training on ImageNet).\n",
    "            If weights='imagenet' input channels must be equal to 3.\n",
    "    # Returns\n",
    "        An integer shape tuple (may include None entries).\n",
    "    # Raises\n",
    "        ValueError: In case of invalid argument values.\n",
    "    \"\"\"\n",
    "    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape[0] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[0]) + ' input channels.')\n",
    "            default_shape = (input_shape[0], default_size, default_size)\n",
    "        else:\n",
    "            if input_shape[-1] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[-1]) + ' input channels.')\n",
    "            default_shape = (default_size, default_size, input_shape[-1])\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            default_shape = (3, default_size, default_size)\n",
    "        else:\n",
    "            default_shape = (default_size, default_size, 3)\n",
    "    if weights == 'imagenet' and require_flatten:\n",
    "        if input_shape is not None:\n",
    "            if input_shape != default_shape:\n",
    "                raise ValueError('When setting `include_top=True` '\n",
    "                                 'and loading `imagenet` weights, '\n",
    "                                 '`input_shape` should be ' +\n",
    "                                 str(default_shape) + '.')\n",
    "        return default_shape\n",
    "    if input_shape:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[0] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n",
    "                   (input_shape[2] is not None and input_shape[2] < min_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_size) + 'x' + str(min_size) +\n",
    "                                     '; got `input_shape=' +\n",
    "                                     str(input_shape) + '`')\n",
    "        else:\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[-1] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
    "                   (input_shape[1] is not None and input_shape[1] < min_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_size) + 'x' + str(min_size) +\n",
    "                                     '; got `input_shape=' +\n",
    "                                     str(input_shape) + '`')\n",
    "    else:\n",
    "        if require_flatten:\n",
    "            input_shape = default_shape\n",
    "        else:\n",
    "            if data_format == 'channels_first':\n",
    "                input_shape = (3, None, None)\n",
    "            else:\n",
    "                input_shape = (None, None, 3)\n",
    "    if require_flatten:\n",
    "        if None in input_shape:\n",
    "            raise ValueError('If `include_top` is True, '\n",
    "                             'you should specify a static `input_shape`. '\n",
    "                             'Got `input_shape=' + str(input_shape) + '`')\n",
    "    return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_input(x, data_format=None, mode='caffe', **kwargs):\n",
    "    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: Input Numpy or symbolic tensor, 3D or 4D.\n",
    "            The preprocessed data is written over the input data\n",
    "            if the data types are compatible. To avoid this\n",
    "            behaviour, `numpy.copy(x)` can be used.\n",
    "        data_format: Data format of the image tensor/array.\n",
    "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
    "            - caffe: will convert the images from RGB to BGR,\n",
    "                then will zero-center each color channel with\n",
    "                respect to the ImageNet dataset,\n",
    "                without scaling.\n",
    "            - tf: will scale pixels between -1 and 1,\n",
    "                sample-wise.\n",
    "            - torch: will scale pixels between 0 and 1 and then\n",
    "                will normalize each channel with respect to the\n",
    "                ImageNet dataset.\n",
    "    # Returns\n",
    "        Preprocessed tensor or Numpy array.\n",
    "    # Raises\n",
    "        ValueError: In case of unknown `data_format` argument.\n",
    "    \"\"\"\n",
    "    backend, _, _, _ = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if data_format is None:\n",
    "        data_format = backend.image_data_format()\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('Unknown data_format ' + str(data_format))\n",
    "\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return _preprocess_numpy_input(x, data_format=data_format,\n",
    "                                       mode=mode, **kwargs)\n",
    "    else:\n",
    "        return _preprocess_symbolic_input(x, data_format=data_format,\n",
    "                                          mode=mode, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_WEIGHTS_PATH = (\n",
    "    'https://github.com/Callidior/keras-applications/'\n",
    "    'releases/download/efficientnet/')\n",
    "\n",
    "IMAGENET_WEIGHTS_HASHES = {\n",
    "    'efficientnet-b0': ('163292582f1c6eaca8e7dc7b51b01c61'\n",
    "                        '5b0dbc0039699b4dcd0b975cc21533dc',\n",
    "                        'c1421ad80a9fc67c2cc4000f666aa507'\n",
    "                        '89ce39eedb4e06d531b0c593890ccff3'),\n",
    "    'efficientnet-b1': ('d0a71ddf51ef7a0ca425bab32b7fa7f1'\n",
    "                        '6043ee598ecee73fc674d9560c8f09b0',\n",
    "                        '75de265d03ac52fa74f2f510455ba64f'\n",
    "                        '9c7c5fd96dc923cd4bfefa3d680c4b68'),\n",
    "    'efficientnet-b2': ('bb5451507a6418a574534aa76a91b106'\n",
    "                        'f6b605f3b5dde0b21055694319853086',\n",
    "                        '433b60584fafba1ea3de07443b74cfd3'\n",
    "                        '2ce004a012020b07ef69e22ba8669333'),\n",
    "    'efficientnet-b3': ('03f1fba367f070bd2545f081cfa7f3e7'\n",
    "                        '6f5e1aa3b6f4db700f00552901e75ab9',\n",
    "                        'c5d42eb6cfae8567b418ad3845cfd63a'\n",
    "                        'a48b87f1bd5df8658a49375a9f3135c7'),\n",
    "    'efficientnet-b4': ('98852de93f74d9833c8640474b2c698d'\n",
    "                        'b45ec60690c75b3bacb1845e907bf94f',\n",
    "                        '7942c1407ff1feb34113995864970cd4'\n",
    "                        'd9d91ea64877e8d9c38b6c1e0767c411'),\n",
    "    'efficientnet-b5': ('30172f1d45f9b8a41352d4219bf930ee'\n",
    "                        '3339025fd26ab314a817ba8918fefc7d',\n",
    "                        '9d197bc2bfe29165c10a2af8c2ebc675'\n",
    "                        '07f5d70456f09e584c71b822941b1952'),\n",
    "    'efficientnet-b6': ('f5270466747753485a082092ac9939ca'\n",
    "                        'a546eb3f09edca6d6fff842cad938720',\n",
    "                        '1d0923bb038f2f8060faaf0a0449db4b'\n",
    "                        '96549a881747b7c7678724ac79f427ed'),\n",
    "    'efficientnet-b7': ('876a41319980638fa597acbbf956a82d'\n",
    "                        '10819531ff2dcb1a52277f10c7aefa1a',\n",
    "                        '60b56ff3a8daccc8d96edfd40b204c11'\n",
    "                        '3e51748da657afd58034d54d3cec2bac')\n",
    "}\n",
    "\n",
    "NS_WEIGHTS_PATH = 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/'\n",
    "NS_WEIGHTS_HASHES = {\n",
    "    'efficientnet-b0': ('5e376ca93bc6ba60f5245d13d44e4323', 'a5b48ae7547fc990c7e4f3951230290d'),\n",
    "    'efficientnet-b1': ('79d29151fdaec95ac78e1ca97fc09634', '4d35baa41ca36f175506a33918f7e334'),\n",
    "    'efficientnet-b2': ('8c643222ffb73a2bfdbdf90f2cde01af', 'e496e531f41242598288ff3a4b4199f9'),\n",
    "    'efficientnet-b3': ('3b29e32602dad75d1f575d9ded00f930', '47da5b154de1372b557a65795d3e6135'),\n",
    "    'efficientnet-b4': ('c000bfa03bf3c93557851b4e1fe18f51', '47c10902a4949eec589ab92fe1c35ed8'),\n",
    "    'efficientnet-b5': ('8a920cd4ee793f53c251a1ecd3a5cee6', '4d53ef3544d4114e2d8080d6d777a74c'),\n",
    "    'efficientnet-b6': ('cc69df409516ab57e30e51016326853e', '71f96d7e15d9f891f3729b4f4e701f77'),\n",
    "    'efficientnet-b7': ('1ac825752cbc26901c8952e030ae4dd9', 'e112b00c464fe929b821edbb35d1af55')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_KERAS_BACKEND = None\n",
    "_KERAS_LAYERS = None\n",
    "_KERAS_MODELS = None\n",
    "_KERAS_UTILS = None\n",
    "\n",
    "def get_submodules_from_kwargs(kwargs):\n",
    "    #backend = kwargs.get('backend', _KERAS_BACKEND)\n",
    "    backend=keras.backend\n",
    "    #layers = kwargs.get('layers', _KERAS_LAYERS)\n",
    "    layers = keras.layers\n",
    "    #models = kwargs.get('models', _KERAS_MODELS)\n",
    "    models = tf.keras.models\n",
    "    utils = kwargs.get('utils', _KERAS_UTILS)\n",
    "    for key in kwargs.keys():\n",
    "        if key not in ['backend', 'layers', 'models', 'utils']:\n",
    "            raise TypeError('Invalid keyword argument: %s', key)\n",
    "    return backend, layers, models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors, Pavel Yakubovskiy, Björn Barz. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Contains definitions for EfficientNet model.\n",
    "[1] Mingxing Tan, Quoc V. Le\n",
    "  EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n",
    "  ICML'19, https://arxiv.org/abs/1905.11946\n",
    "\"\"\"\n",
    "\n",
    "# Code of this model implementation is mostly written by\n",
    "# Björn Barz ([@Callidior](https://github.com/Callidior))\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from six.moves import xrange\n",
    "#from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "#from keras_applications.imagenet_utils import preprocess_input as _preprocess_input\n",
    "\n",
    "#from . import get_submodules_from_kwargs\n",
    "#from .weights import IMAGENET_WEIGHTS_PATH, IMAGENET_WEIGHTS_HASHES, NS_WEIGHTS_HASHES, NS_WEIGHTS_PATH\n",
    "\n",
    "backend = None\n",
    "layers = None\n",
    "models = None\n",
    "keras_utils = None\n",
    "\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'strides', 'se_ratio'\n",
    "])\n",
    "# defaults will be a public argument for namedtuple in Python 3.7\n",
    "# https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "\n",
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n",
    "              expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25)\n",
    "]\n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1. / 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'uniform'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_input(x, **kwargs):\n",
    "    kwargs = {k: v for k, v in kwargs.items() if k in ['backend', 'layers', 'models', 'utils']}\n",
    "    return _preprocess_input(x, mode='torch', **kwargs)\n",
    "\n",
    "\n",
    "def get_swish(**kwargs):\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    def swish(x):\n",
    "        \"\"\"Swish activation function: x * sigmoid(x).\n",
    "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "        \"\"\"\n",
    "\n",
    "        if backend.backend() == 'tensorflow':\n",
    "            try:\n",
    "                # The native TF implementation has a more\n",
    "                # memory-efficient gradient implementation\n",
    "                return backend.tf.nn.swish(x)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "        return x * backend.sigmoid(x)\n",
    "\n",
    "    return swish\n",
    "\n",
    "\n",
    "def get_dropout(**kwargs):\n",
    "    \"\"\"Wrapper over custom dropout. Fix problem of ``None`` shape for tf.keras.\n",
    "    It is not possible to define FixedDropout class as global object,\n",
    "    because we do not have modules for inheritance at first time.\n",
    "    Issue:\n",
    "        https://github.com/tensorflow/tensorflow/issues/30946\n",
    "    \"\"\"\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    class FixedDropout(layers.Dropout):\n",
    "        def _get_noise_shape(self, inputs):\n",
    "            if self.noise_shape is None:\n",
    "                return self.noise_shape\n",
    "\n",
    "            symbolic_shape = backend.shape(inputs)\n",
    "            noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                           for axis, shape in enumerate(self.noise_shape)]\n",
    "            return tuple(noise_shape)\n",
    "\n",
    "    #return FixedDropout\n",
    "    return Dropout\n",
    "\n",
    "\n",
    "def round_filters(filters, width_coefficient, depth_divisor):\n",
    "    \"\"\"Round number of filters based on width multiplier.\"\"\"\n",
    "\n",
    "    filters *= width_coefficient\n",
    "    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
    "    new_filters = max(depth_divisor, new_filters)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_filters < 0.9 * filters:\n",
    "        new_filters += depth_divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "def round_repeats(repeats, depth_coefficient):\n",
    "    \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "\n",
    "    return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "\n",
    "def mb_conv_block(inputs, block_args, activation, drop_rate=None, prefix='', ):\n",
    "    \"\"\"Mobile Inverted Residual Bottleneck.\"\"\"\n",
    "\n",
    "    has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    # workaround over non working dropout with None in noise_shape in tf.keras\n",
    "    Dropout = get_dropout(\n",
    "        backend=backend,\n",
    "        layers=layers,\n",
    "        models=models,\n",
    "        utils=keras_utils\n",
    "    )\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = block_args.input_filters * block_args.expand_ratio\n",
    "    if block_args.expand_ratio != 1:\n",
    "        x = layers.Conv2D(filters, 1,\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                          name=prefix + 'expand_conv')(inputs)\n",
    "        x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'expand_bn')(x)\n",
    "        x = layers.Activation(activation, name=prefix + 'expand_activation')(x)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    x = layers.DepthwiseConv2D(block_args.kernel_size,\n",
    "                               strides=block_args.strides,\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=prefix + 'dwconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'bn')(x)\n",
    "    x = layers.Activation(activation, name=prefix + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if has_se:\n",
    "        num_reduced_filters = max(1, int(\n",
    "            block_args.input_filters * block_args.se_ratio\n",
    "        ))\n",
    "        se_tensor = layers.GlobalAveragePooling2D(name=prefix + 'se_squeeze')(x)\n",
    "\n",
    "        target_shape = (1, 1, filters) if backend.image_data_format() == 'channels_last' else (filters, 1, 1)\n",
    "        se_tensor = layers.Reshape(target_shape, name=prefix + 'se_reshape')(se_tensor)\n",
    "        se_tensor = layers.Conv2D(num_reduced_filters, 1,\n",
    "                                  activation=activation,\n",
    "                                  padding='same',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                                  name=prefix + 'se_reduce')(se_tensor)\n",
    "        se_tensor = layers.Conv2D(filters, 1,\n",
    "                                  activation='sigmoid',\n",
    "                                  padding='same',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                                  name=prefix + 'se_expand')(se_tensor)\n",
    "        if backend.backend() == 'theano':\n",
    "            # For the Theano backend, we have to explicitly make\n",
    "            # the excitation weights broadcastable.\n",
    "            pattern = ([True, True, True, False] if backend.image_data_format() == 'channels_last'\n",
    "                       else [True, False, True, True])\n",
    "            se_tensor = layers.Lambda(\n",
    "                lambda x: backend.pattern_broadcast(x, pattern),\n",
    "                name=prefix + 'se_broadcast')(se_tensor)\n",
    "        x = layers.multiply([x, se_tensor], name=prefix + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    x = layers.Conv2D(block_args.output_filters, 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=prefix + 'project_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'project_bn')(x)\n",
    "    if block_args.id_skip and all(\n",
    "            s == 1 for s in block_args.strides\n",
    "    ) and block_args.input_filters == block_args.output_filters:\n",
    "        if drop_rate and (drop_rate > 0):\n",
    "            x = Dropout(drop_rate,\n",
    "                        noise_shape=(None, 1, 1, 1),\n",
    "                        name=prefix + 'drop')(x)\n",
    "        x = layers.add([x, inputs], name=prefix + 'add')\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def EfficientNet(width_coefficient,\n",
    "                 depth_coefficient,\n",
    "                 default_resolution,\n",
    "                 dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2,\n",
    "                 depth_divisor=8,\n",
    "                 blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "                 model_name='efficientnet',\n",
    "                 include_top=True,\n",
    "                 weights='imagenet',\n",
    "                 input_tensor=None,\n",
    "                 input_shape=None,\n",
    "                 pooling=None,\n",
    "                 classes=1000,\n",
    "                 **kwargs):\n",
    "    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        width_coefficient: float, scaling coefficient for network width.\n",
    "        depth_coefficient: float, scaling coefficient for network depth.\n",
    "        default_resolution: int, default input image size.\n",
    "        dropout_rate: float, dropout rate before final classifier layer.\n",
    "        drop_connect_rate: float, dropout rate at skip connections.\n",
    "        depth_divisor: int.\n",
    "        blocks_args: A list of BlockArgs to construct block modules.\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False.\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    global backend, layers, models, keras_utils\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if not (weights in {'imagenet', 'noisy-student', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=default_resolution,\n",
    "                                      min_size=32,\n",
    "                                      data_format=backend.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if backend.backend() == 'tensorflow':\n",
    "            from tensorflow.python.keras.backend import is_keras_tensor\n",
    "        else:\n",
    "            is_keras_tensor = backend.is_keras_tensor\n",
    "        if not is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    #activation = get_swish(**kwargs)\n",
    "    activation = \"relu\"\n",
    "\n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.Conv2D(round_filters(32, width_coefficient, depth_divisor), 3,\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name='stem_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)\n",
    "    x = layers.Activation(activation, name='stem_activation')(x)\n",
    "\n",
    "    # Build blocks\n",
    "    num_blocks_total = sum(block_args.num_repeat for block_args in blocks_args)\n",
    "    block_num = 0\n",
    "    for idx, block_args in enumerate(blocks_args):\n",
    "        assert block_args.num_repeat > 0\n",
    "        # Update block input and output filters based on depth multiplier.\n",
    "        block_args = block_args._replace(\n",
    "            input_filters=round_filters(block_args.input_filters,\n",
    "                                        width_coefficient, depth_divisor),\n",
    "            output_filters=round_filters(block_args.output_filters,\n",
    "                                         width_coefficient, depth_divisor),\n",
    "            num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n",
    "\n",
    "        # The first block needs to take care of stride and filter size increase.\n",
    "        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "        x = mb_conv_block(x, block_args,\n",
    "                          activation=activation,\n",
    "                          drop_rate=drop_rate,\n",
    "                          prefix='block{}a_'.format(idx + 1))\n",
    "        block_num += 1\n",
    "        if block_args.num_repeat > 1:\n",
    "            # pylint: disable=protected-access\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=block_args.output_filters, strides=[1, 1])\n",
    "            # pylint: enable=protected-access\n",
    "            for bidx in xrange(block_args.num_repeat - 1):\n",
    "                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "                block_prefix = 'block{}{}_'.format(\n",
    "                    idx + 1,\n",
    "                    string.ascii_lowercase[bidx + 1]\n",
    "                )\n",
    "                x = mb_conv_block(x, block_args,\n",
    "                                  activation=activation,\n",
    "                                  drop_rate=drop_rate,\n",
    "                                  prefix=block_prefix)\n",
    "                block_num += 1\n",
    "\n",
    "    # Build top\n",
    "    x = layers.Conv2D(round_filters(1280, width_coefficient, depth_divisor), 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name='top_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)\n",
    "    x = layers.Activation(activation, name='top_activation')(x)\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        if dropout_rate and dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate, name='top_dropout')(x)\n",
    "        x = layers.Dense(classes,\n",
    "                         activation='softmax',\n",
    "                         kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "                         name='probs')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "\n",
    "        if include_top:\n",
    "            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_autoaugment.h5'\n",
    "            file_hash = IMAGENET_WEIGHTS_HASHES[model_name][0]\n",
    "        else:\n",
    "            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "            file_hash = IMAGENET_WEIGHTS_HASHES[model_name][1]\n",
    "        weights_path = keras_utils.get_file(\n",
    "            file_name,\n",
    "            IMAGENET_WEIGHTS_PATH + file_name,\n",
    "            cache_subdir='models',\n",
    "            file_hash=file_hash,\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    elif weights == 'noisy-student':\n",
    "\n",
    "        if include_top:\n",
    "            file_name = \"{}_{}.h5\".format(model_name, weights)\n",
    "            file_hash = NS_WEIGHTS_HASHES[model_name][0]\n",
    "        else:\n",
    "            file_name = \"{}_{}_notop.h5\".format(model_name, weights)\n",
    "            file_hash = NS_WEIGHTS_HASHES[model_name][1]\n",
    "        weights_path = keras_utils.get_file(\n",
    "            file_name,\n",
    "            NS_WEIGHTS_PATH + file_name,\n",
    "            cache_subdir='models',\n",
    "            file_hash=file_hash,\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def EfficientNetB0(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0, 1.0, 224, 0.2,\n",
    "        model_name='efficientnet-b0',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB1(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0, 1.1, 240, 0.2,\n",
    "        model_name='efficientnet-b1',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB2(include_top=True,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=1000,\n",
    "                   **kwargs):\n",
    "    return EfficientNet(\n",
    "        1.1, 1.2, 260, 0.3,\n",
    "        model_name='efficientnet-b2',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB3(include_top=True,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=1000,\n",
    "                   **kwargs):\n",
    "    return EfficientNet(\n",
    "        1.2, 1.4, 300, 0.3,\n",
    "        model_name='efficientnet-b3',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB4(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.4, 1.8, 380, 0.4,\n",
    "        model_name='efficientnet-b4',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB5(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.6, 2.2, 456, 0.4,\n",
    "        model_name='efficientnet-b5',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB6(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.8, 2.6, 528, 0.5,\n",
    "        model_name='efficientnet-b6',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB7(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        2.0, 3.1, 600, 0.5,\n",
    "        model_name='efficientnet-b7',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetL2(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        4.3, 5.3, 800, 0.5,\n",
    "        model_name='efficientnet-l2',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "setattr(EfficientNetB0, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB1, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB2, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB3, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB4, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB5, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB6, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB7, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetL2, '__doc__', EfficientNet.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando EfficientNet para obtener capa tipo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_tfkeras_modules(func):\n",
    "    import tensorflow.keras as tfkeras\n",
    "    #@functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        kwargs['backend'] = tfkeras.backend\n",
    "        kwargs['layers'] = tfkeras.layers\n",
    "        kwargs['models'] = tfkeras.models\n",
    "        kwargs['utils'] = tfkeras.utils\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNetB0 = inject_tfkeras_modules(EfficientNetB0)\n",
    "EfficientNetB1 = inject_tfkeras_modules(EfficientNetB1)\n",
    "EfficientNetB2 = inject_tfkeras_modules(EfficientNetB2)\n",
    "EfficientNetB3 = inject_tfkeras_modules(EfficientNetB3)\n",
    "EfficientNetB4 = inject_tfkeras_modules(EfficientNetB4)\n",
    "EfficientNetB5 = inject_tfkeras_modules(EfficientNetB5)\n",
    "EfficientNetB6 = inject_tfkeras_modules(EfficientNetB6)\n",
    "EfficientNetB7 = inject_tfkeras_modules(EfficientNetB7)\n",
    "EfficientNetL2 = inject_tfkeras_modules(EfficientNetL2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el modelo EfficientNet con pesos preentrenados en ImageNet\n",
    "#rnet = efn.EfficientNetB7(weights=None, include_top=False, input_shape=[128,128,3])\n",
    "#rnet = tf.keras.applications.EfficientNetB7(weights=None, include_top=False, input_shape=[128,128,3]) # Tensoorflow 2.3.0 en adelante\n",
    "rnet = EfficientNetB7(weights=None, include_top=False, input_shape=[128,128,3])\n",
    "rnet = tf.keras.Sequential(rnet)\n",
    "rnet.add(Dropout(rate=dropout))\n",
    "rnet.add(Flatten())\n",
    "rnet.add(Dense(4096, activation='relu'))\n",
    "rnet.add(Dropout(rate=dropout))\n",
    "rnet.add(Dense(4096, activation='relu'))\n",
    "rnet.add(Dropout(rate=dropout))\n",
    "rnet.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.training.Model at 0x7fa93c079850>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fabf853bad0>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x7fa914139a10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fa8f2473250>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fa900244b50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fa914544510>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fa91409e950>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fa8f26d9150>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnet.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b7 (Model)      (None, 4, 4, 2560)        64097680  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 2560)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40960)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              167776256 \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 248,659,345\n",
      "Trainable params: 248,348,625\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnet.load_weights('EFNB7_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnet.save('modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFNB7_weights.h5  modelo.h5  modelo.tar.gz  T0032.1.1.D.2016-10-29.16.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprimiendo modelo EfiicientNet en formato tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo.h5\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf modelo.tar.gz modelo.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFNB7_weights.h5  modelo.h5  modelo.tar.gz  T0032.1.1.D.2016-10-29.16.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando la dirección del modelo tar.gz\n",
    "model_path = '/home/wsuser/work/modelo.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02154853]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnet.predict(X_prueba_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Tensorflow desplegado en la nube\n",
    "\n",
    "Aquí se describen los pasos para almaenar el modelo EfficientNet en el repositorio de Watson Machine Learningn utilizando el SDK de IBM Watson Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publicando modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiendo nombre del modelo, nombre del autor y el software específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sofware_spec_uid = client.software_specifications.get_id_by_name(\"tensorflow_2.1-py3.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metadata = {\n",
    "            client.repository.ModelMetaNames.NAME: 'EfficientNetB7',\n",
    "            client.repository.ModelMetaNames.TYPE: 'tensorflow_2.1',\n",
    "            client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid\n",
    "}\n",
    "\n",
    "published_model = client.repository.store_model(\n",
    "    model=model_path,\n",
    "    meta_props=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obteniendo detalles del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"entity\": {\n",
      "    \"software_spec\": {\n",
      "      \"id\": \"cXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
      "      \"name\": \"tensorflow_2.1-py3.7\"\n",
      "    },\n",
      "    \"type\": \"tensorflow_2.1\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"created_at\": \"2020-12-04T02:17:10.369Z\",\n",
      "    \"id\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
      "    \"modified_at\": \"2020-12-04T02:17:37.235Z\",\n",
      "    \"name\": \"EfficientNetB7\",\n",
      "    \"owner\": \"IBMid-550009WDCT\",\n",
      "    \"space_id\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
      "  },\n",
      "  \"system\": {\n",
      "    \"warnings\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(published_model_uid)\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  --------------  ------------------------  --------------\n",
      "ID                                    NAME            CREATED                   TYPE\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  EfficientNetB7  2020-12-04T02:17:10.002Z  tensorflow_2.1\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  EfficientNetB7  2020-12-04T02:07:29.002Z  tensorflow_2.1\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  EfficientNetB7  2020-12-04T00:56:48.002Z  tensorflow_2.1\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  EfficientNetB7  2020-12-04T00:23:59.002Z  tensorflow_2.1\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  EfficientNetB7  2020-12-03T23:26:27.002Z  tensorflow_2.1\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  EfficientNetB7  2020-12-03T22:41:42.002Z  tensorflow_2.1\n",
      "------------------------------------  --------------  ------------------------  --------------\n"
     ]
    }
   ],
   "source": [
    "models_details = client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desplegando y almacenando en una nube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se almacena el modelo para poder obtener un score de forma online uutilizando solicitudes tipo con arreglos tipo json con ayuda de IBM Watson Machine Learning SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando modelo desplegado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creando despliegue online para el modelo publicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "initializing................\n",
      "ready\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"Deployment of external Tensorflow model\",\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}\n",
    "\n",
    "created_deployment = client.deployments.create(published_model_uid, meta_props=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b7 (Model)      (None, 4, 4, 2560)        64097680  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 2560)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40960)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              167776256 \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 248,659,345\n",
      "Trainable params: 248,348,625\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_uid = client.deployments.get_uid(created_deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos imprimir el \"online scoring endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://us-south.ml.cloud.ibm.com/ml/v4/deployments/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/predictions\n"
     ]
    }
   ],
   "source": [
    "scoring_endpoint = client.deployments.get_scoring_href(created_deployment)\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list existing deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ---------------------------------------  ------  ------------------------\n",
      "GUID                                  NAME                                     STATE   CREATED\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  Deployment of external Tensorflow model  ready   2020-12-04T02:17:40.026Z\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  Deployment of external Tensorflow model  failed  2020-12-04T02:08:15.442Z\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  Deployment of external Tensorflow model  failed  2020-12-04T00:59:56.165Z\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  Deployment of external Tensorflow model  failed  2020-12-04T00:24:36.800Z\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  Deployment of external Tensorflow model  failed  2020-12-03T23:28:05.407Z\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX  Deployment of external Tensorflow model  failed  2020-12-03T22:43:00.904Z\n",
      "------------------------------------  ---------------------------------------  ------  ------------------------\n"
     ]
    }
   ],
   "source": [
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obteniendo detalles del \"despliegue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': {'asset': {'id': 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'},\n",
       "  'custom': {},\n",
       "  'deployed_asset_type': 'model',\n",
       "  'hardware_spec': {'id': 'Not_Applicable', 'name': 'XS', 'num_nodes': 1},\n",
       "  'name': 'Deployment of external Tensorflow model',\n",
       "  'online': {},\n",
       "  'space_id': 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',\n",
       "  'status': {'online_url': {'url': 'https://us-south.ml.cloud.ibm.com/ml/v4/deployments/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/predictions'},\n",
       "   'state': 'ready'}},\n",
       " 'metadata': {'created_at': '2020-12-04T02:17:40.026Z',\n",
       "  'id': 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',\n",
       "  'modified_at': '2020-12-04T02:17:40.026Z',\n",
       "  'name': 'Deployment of external Tensorflow model',\n",
       "  'owner': 'IBMid-550009WDCT',\n",
       "  'space_id': 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.get_details(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a realizar una prueba de acceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_0 = X_prueba_128.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scoring_payload = {\"input_data\": [{\"values\": [score_0[0]]}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el método ``client.deployments.score()``para probar el modelo en la nube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = client.deployments.score(deployment_uid, scoring_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the result of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    {\n",
      "      \"id\": \"dense_5\",\n",
      "      \"fields\": [\n",
      "        \"prediction\",\n",
      "        \"prediction_classes\",\n",
      "        \"probability\"\n",
      "      ],\n",
      "      \"values\": [\n",
      "        [\n",
      "          [\n",
      "            0.021548686549067497\n",
      "          ],\n",
      "          [\n",
      "            0\n",
      "          ],\n",
      "          [\n",
      "            0.021548686549067497\n",
      "          ]\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos la probabilidad de cáncer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021548686549067497"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo Online\n",
    "predictions['predictions'][0]['values'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo \"local\"\n",
    "rnet.predict(score_0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
