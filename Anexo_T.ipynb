{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7DT89f3OzOf"
   },
   "source": [
    "Anexo T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPDcUj7fPPg3"
   },
   "source": [
    "# Utilizando Google Colab para realizar petición (Query) a Red Neuronal Convolucional EffcientNet alojada en IBM Watson.\n",
    "\n",
    "#### Elaborado por: Ricardo Niño de Rivera Barrón\n",
    "\n",
    "#### Ingeniería Biónica\n",
    "\n",
    "#### Trabajo Terminal II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZueJZaSoZTp"
   },
   "source": [
    "En esta libreta interactiva se hace una demostración de acceso al modelo deplegado en IBM Watson desde el entorno de Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q--ZAMOTP0Kq"
   },
   "source": [
    "Instalamos biblioteca para entablar comunicación con MEGA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--UI7kNsQLCJ",
    "outputId": "9cb9c8cd-be8a-4372-d159-df0f32e6ca0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mega.py\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/51/44a1085a091c27ade09e122d5abdafb4b6400265081879a7c4e32973a175/mega.py-1.0.8-py2.py3-none-any.whl\n",
      "Collecting tenacity<6.0.0,>=5.1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/45/67/67bb1db087678bc5c6f20766cf18914dfe37b0b9d4e4c5bb87408460b75f/tenacity-5.1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.6/dist-packages (from mega.py) (1.0.1)\n",
      "Requirement already satisfied: requests>=0.10 in /usr/local/lib/python3.6/dist-packages (from mega.py) (2.23.0)\n",
      "Collecting pycryptodome<4.0.0,>=3.9.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/6f/7e38d7c97fbbc3987539c804282c33f56b6b07381bf2390deead696440c5/pycryptodome-3.9.9-cp36-cp36m-manylinux1_x86_64.whl (13.7MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7MB 10.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tenacity<6.0.0,>=5.1.5->mega.py) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=0.10->mega.py) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=0.10->mega.py) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=0.10->mega.py) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=0.10->mega.py) (3.0.4)\n",
      "Installing collected packages: tenacity, pycryptodome, mega.py\n",
      "Successfully installed mega.py-1.0.8 pycryptodome-3.9.9 tenacity-5.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install mega.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7KXnbMC8QV6S"
   },
   "outputs": [],
   "source": [
    "# De la biblioteca mega importamos el método Mega\n",
    "from mega import Mega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VTV8XGx7QaLy"
   },
   "outputs": [],
   "source": [
    "# Instanciando Mega en el objeto mega\n",
    "mega = Mega()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8IObsixQuLL"
   },
   "source": [
    "Inicamos sesión en MEGA con cuenta temporal y anónima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1w6LfIIFQaJP"
   },
   "outputs": [],
   "source": [
    "# Log in en la cuenta de MEGA con cuenta temporal anónima\n",
    "m = mega.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Hh4PtrlRCwQ",
    "outputId": "aedc624b-5a65-417b-fcf0-d9290df6f9e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('X_train.npy')"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargando el archivo X_train.npy\n",
    "m.download_url('https://mega.nz/file/oAZT1IYJ#HpIvnnR50IH6N2F9wfdPgNTgLPpAwhEBpTl3_yAxLFc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mP8nYyPKQaGS",
    "outputId": "d180c6c9-ab54-4aa4-80ad-51bcfd1ed90d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  X_train.npy\n"
     ]
    }
   ],
   "source": [
    "# Mostrando archivos en el directorio de trabajo del entorno\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnbeBy0XQaEI",
    "outputId": "e7cd6aec-3070-4cc6-b88c-451ed926d522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('X_test.npy')"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargando el archivo X_test.npy\n",
    "m.download_url('https://mega.nz/file/tMIzDQbK#MLFeDRu5D4dq2lRqvPcxIZkuTtVKH2azBRrhSzndqME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9X1RUkxQaBs",
    "outputId": "3cc0c40f-e44c-4a90-febe-e9e314f6d821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "# Imprimiendo el directorio de trabajo\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUPvX6lqrYfk",
    "outputId": "da24e9cf-c19c-49d2-b52c-220bac37b8f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('T0032.1.1.D.2016-10-29.16.npy')"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargando el archivo de prueba T0032.1.1.D.2016-10-29.16.npy\n",
    "m.download_url('https://mega.nz/file/URwlCCpC#It8L-P9xJexCtwgFY2q1NbXkEH8A9aVg9JWZfedLLjw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kik9mrGMrYfk",
    "outputId": "dd3e75fd-4824-484b-8477-947d493d6be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  T0032.1.1.D.2016-10-29.16.npy  X_test.npy\tX_train.npy\n"
     ]
    }
   ],
   "source": [
    "# Mostrando archivos en el directorio de trabajo del entorno\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ClweYYmrYfl",
    "outputId": "0977b40d-e67c-4169-ee9f-1c4401125e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "# Imprimiendo el directorio de trabajo\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnzrZMPzrYfl"
   },
   "source": [
    "Leyendo archivo con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rtb8TNdFrYfl"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57qDfJaIrYfl",
    "outputId": "7d52b9cc-d135-4ed5-f2cf-865a4106a970"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prueba = np.load('T0032.1.1.D.2016-10-29.16.npy')\n",
    "X_prueba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IOjH-QFrYfq"
   },
   "source": [
    "## Acondicionando imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4kg6ECrSrYfq"
   },
   "outputs": [],
   "source": [
    "# # importando bibliotecas auxiliares\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y6pH3sGDrYfq"
   },
   "outputs": [],
   "source": [
    "# Definiendo función get_img para leer los archivos numpy y ajustarlos a nuevo tamaño.\n",
    "# La imagen que retorna la función también es normalizada sobre los valor máximo del pixel (255)\n",
    "def get_img(imagen, size=128):\n",
    "    \n",
    "    img = np.expand_dims(imagen, axis=2)\n",
    "    \n",
    "    return tf.image.resize(img, [size,size], antialias=True)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9N1gp0g0rYfq",
    "outputId": "53b54125-2542-4d63-fb6b-8993087d5114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 128, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prueba = get_img(X_prueba)\n",
    "X_prueba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pO03YjtdrYfq"
   },
   "outputs": [],
   "source": [
    "# X_prueba_128\n",
    "\n",
    "X_prueba_128 = np.zeros((1, 128, 128,3))\n",
    "\n",
    "# Almacenamos la imagen obtenida en cada canal\n",
    "X_prueba_128[0,:,:,0] = X_prueba[:,:,0]\n",
    "X_prueba_128[0,:,:,1] = X_prueba[:,:,0]\n",
    "X_prueba_128[0,:,:,2] = X_prueba[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uk-JLjcBrYfq",
    "outputId": "2f557cf7-5925-4859-ef24-98c1f5834d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  T0032.1.1.D.2016-10-29.16.npy  X_test.npy\tX_train.npy\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYlmpXpprYfr"
   },
   "source": [
    "### Descargando los archivos del modelo EfficientNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMEq2GlqrYfr"
   },
   "source": [
    "Descargando archivos desde Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Ndo17_FrYfr",
    "outputId": "9ccc933c-2f98-4760-fba9-9b13b459ab0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-04 12:52:39--  https://www.kaggleusercontent.com/kf/48361538/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..njsffmmrxkhGXxE2Msz07w.B4U8OaptAFkENshabpblG6C61Ma6sDAFrm048NXN5YuPUKXVaWgZFYOamYmPn6cLt2hYFwz8jV8FmgcTYQb5wo9K89DEaZe9Sf7EeJaRyO7NcArmtiialGFJU-u003aCnshNT3tAArb0-XLc_i0fWlXm5TXLbbUdi9ui3MQDXV3bHuWsXfvECSZqoaJvONsSAnqBV3bkuyktmvWtjkD-1da1JapNK772CELV5HQ4t6xaMIdCpmUpLqrktIgHVNhXZCPZqnyeF_2oiTotGyxdEOswYi6V_AoyfEOENboez34H6tBLd5wnuNXooLB--xpvKFu821ChssAp5rZzyOX983HuT5X3-7UPAjxosbrEtqQS9jLthf_7WaYLGXxXKo0zBANi_je9OCP1ddB1sta1HPujK8KCcsFQX4x6IXiyjoXh5qoDZKsutwdB0Tg6jmJA1fs6b0lDzUjWo749HzGEHmVh16wnyfIyVHBZd-ZSUszwVLZjsdRIRNA2br3joCdgJO2nQrrxZ9MlEO-efmeEohdxgBHF5p0uejLASQdj7GHsrbtaBVFN2qRmdYIgwufbZgw_xW_COhSmkzNQ2NOw_4NsFLpH_w0eAS_ZtZoPrTeBZAeTPRZsDQhoPA-ToVCH.gdJfq2rX4l7dhlECF6WgFA/EFNB7_weights.h5\n",
      "Resolving www.kaggleusercontent.com (www.kaggleusercontent.com)... 35.190.26.106\n",
      "Connecting to www.kaggleusercontent.com (www.kaggleusercontent.com)|35.190.26.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2984398720 (2.8G) [application/octet-stream]\n",
      "Saving to: ‘EFNB7_weights.h5’\n",
      "\n",
      "EFNB7_weights.h5    100%[===================>]   2.78G  60.6MB/s    in 28s     \n",
      "\n",
      "2020-12-04 12:53:07 (101 MB/s) - ‘EFNB7_weights.h5’ saved [2984398720/2984398720]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descargando archivo con modelo EficienNetB7 EFNB7_weights.h5\n",
    "!wget https://www.kaggleusercontent.com/kf/48361538/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..njsffmmrxkhGXxE2Msz07w.B4U8OaptAFkENshabpblG6C61Ma6sDAFrm048NXN5YuPUKXVaWgZFYOamYmPn6cLt2hYFwz8jV8FmgcTYQb5wo9K89DEaZe9Sf7EeJaRyO7NcArmtiialGFJU-u003aCnshNT3tAArb0-XLc_i0fWlXm5TXLbbUdi9ui3MQDXV3bHuWsXfvECSZqoaJvONsSAnqBV3bkuyktmvWtjkD-1da1JapNK772CELV5HQ4t6xaMIdCpmUpLqrktIgHVNhXZCPZqnyeF_2oiTotGyxdEOswYi6V_AoyfEOENboez34H6tBLd5wnuNXooLB--xpvKFu821ChssAp5rZzyOX983HuT5X3-7UPAjxosbrEtqQS9jLthf_7WaYLGXxXKo0zBANi_je9OCP1ddB1sta1HPujK8KCcsFQX4x6IXiyjoXh5qoDZKsutwdB0Tg6jmJA1fs6b0lDzUjWo749HzGEHmVh16wnyfIyVHBZd-ZSUszwVLZjsdRIRNA2br3joCdgJO2nQrrxZ9MlEO-efmeEohdxgBHF5p0uejLASQdj7GHsrbtaBVFN2qRmdYIgwufbZgw_xW_COhSmkzNQ2NOw_4NsFLpH_w0eAS_ZtZoPrTeBZAeTPRZsDQhoPA-ToVCH.gdJfq2rX4l7dhlECF6WgFA/EFNB7_weights.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kN8U8JUlrYfr",
    "outputId": "481ba0f6-e130-4f24-da24-b5f5b0e407dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFNB7_weights.h5  T0032.1.1.D.2016-10-29.16.npy  X_train.npy\n",
      "sample_data\t  X_test.npy\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkvM6tkurYfw"
   },
   "source": [
    "## Definiendo EfficientNet en https://github.com/qubvel/efficientnet/blob/master/efficientnet/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhPuy9l6rYfw"
   },
   "source": [
    "Importando bibliotecas y métodos de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dYn6QijHrYfw"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "o7pn-p9ArYfw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "z-iWUuaprYfw",
    "outputId": "6365ebeb-fdfb-4eec-e90a-9a15525c3864"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lKm0JZvhrYfz"
   },
   "outputs": [],
   "source": [
    "def _obtain_input_shape(input_shape,\n",
    "                        default_size,\n",
    "                        min_size,\n",
    "                        data_format,\n",
    "                        require_flatten,\n",
    "                        weights=None):\n",
    "    \"\"\"Internal utility to compute/validate a model's input shape.\n",
    "    # Arguments\n",
    "        input_shape: Either None (will return the default network input shape),\n",
    "            or a user-provided shape to be validated.\n",
    "        default_size: Default input width/height for the model.\n",
    "        min_size: Minimum input width/height accepted by the model.\n",
    "        data_format: Image data format to use.\n",
    "        require_flatten: Whether the model is expected to\n",
    "            be linked to a classifier via a Flatten layer.\n",
    "        weights: One of `None` (random initialization)\n",
    "            or 'imagenet' (pre-training on ImageNet).\n",
    "            If weights='imagenet' input channels must be equal to 3.\n",
    "    # Returns\n",
    "        An integer shape tuple (may include None entries).\n",
    "    # Raises\n",
    "        ValueError: In case of invalid argument values.\n",
    "    \"\"\"\n",
    "    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape[0] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[0]) + ' input channels.')\n",
    "            default_shape = (input_shape[0], default_size, default_size)\n",
    "        else:\n",
    "            if input_shape[-1] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[-1]) + ' input channels.')\n",
    "            default_shape = (default_size, default_size, input_shape[-1])\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            default_shape = (3, default_size, default_size)\n",
    "        else:\n",
    "            default_shape = (default_size, default_size, 3)\n",
    "    if weights == 'imagenet' and require_flatten:\n",
    "        if input_shape is not None:\n",
    "            if input_shape != default_shape:\n",
    "                raise ValueError('When setting `include_top=True` '\n",
    "                                 'and loading `imagenet` weights, '\n",
    "                                 '`input_shape` should be ' +\n",
    "                                 str(default_shape) + '.')\n",
    "        return default_shape\n",
    "    if input_shape:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[0] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n",
    "                   (input_shape[2] is not None and input_shape[2] < min_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_size) + 'x' + str(min_size) +\n",
    "                                     '; got `input_shape=' +\n",
    "                                     str(input_shape) + '`')\n",
    "        else:\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[-1] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
    "                   (input_shape[1] is not None and input_shape[1] < min_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_size) + 'x' + str(min_size) +\n",
    "                                     '; got `input_shape=' +\n",
    "                                     str(input_shape) + '`')\n",
    "    else:\n",
    "        if require_flatten:\n",
    "            input_shape = default_shape\n",
    "        else:\n",
    "            if data_format == 'channels_first':\n",
    "                input_shape = (3, None, None)\n",
    "            else:\n",
    "                input_shape = (None, None, 3)\n",
    "    if require_flatten:\n",
    "        if None in input_shape:\n",
    "            raise ValueError('If `include_top` is True, '\n",
    "                             'you should specify a static `input_shape`. '\n",
    "                             'Got `input_shape=' + str(input_shape) + '`')\n",
    "    return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "R_R6NhRXrYfz"
   },
   "outputs": [],
   "source": [
    "def _preprocess_input(x, data_format=None, mode='caffe', **kwargs):\n",
    "    \"\"\"Preprocesses a tensor or Numpy array encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: Input Numpy or symbolic tensor, 3D or 4D.\n",
    "            The preprocessed data is written over the input data\n",
    "            if the data types are compatible. To avoid this\n",
    "            behaviour, `numpy.copy(x)` can be used.\n",
    "        data_format: Data format of the image tensor/array.\n",
    "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
    "            - caffe: will convert the images from RGB to BGR,\n",
    "                then will zero-center each color channel with\n",
    "                respect to the ImageNet dataset,\n",
    "                without scaling.\n",
    "            - tf: will scale pixels between -1 and 1,\n",
    "                sample-wise.\n",
    "            - torch: will scale pixels between 0 and 1 and then\n",
    "                will normalize each channel with respect to the\n",
    "                ImageNet dataset.\n",
    "    # Returns\n",
    "        Preprocessed tensor or Numpy array.\n",
    "    # Raises\n",
    "        ValueError: In case of unknown `data_format` argument.\n",
    "    \"\"\"\n",
    "    backend, _, _, _ = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if data_format is None:\n",
    "        data_format = backend.image_data_format()\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('Unknown data_format ' + str(data_format))\n",
    "\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return _preprocess_numpy_input(x, data_format=data_format,\n",
    "                                       mode=mode, **kwargs)\n",
    "    else:\n",
    "        return _preprocess_symbolic_input(x, data_format=data_format,\n",
    "                                          mode=mode, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "hw1OaoUcrYfz"
   },
   "outputs": [],
   "source": [
    "IMAGENET_WEIGHTS_PATH = (\n",
    "    'https://github.com/Callidior/keras-applications/'\n",
    "    'releases/download/efficientnet/')\n",
    "\n",
    "IMAGENET_WEIGHTS_HASHES = {\n",
    "    'efficientnet-b0': ('163292582f1c6eaca8e7dc7b51b01c61'\n",
    "                        '5b0dbc0039699b4dcd0b975cc21533dc',\n",
    "                        'c1421ad80a9fc67c2cc4000f666aa507'\n",
    "                        '89ce39eedb4e06d531b0c593890ccff3'),\n",
    "    'efficientnet-b1': ('d0a71ddf51ef7a0ca425bab32b7fa7f1'\n",
    "                        '6043ee598ecee73fc674d9560c8f09b0',\n",
    "                        '75de265d03ac52fa74f2f510455ba64f'\n",
    "                        '9c7c5fd96dc923cd4bfefa3d680c4b68'),\n",
    "    'efficientnet-b2': ('bb5451507a6418a574534aa76a91b106'\n",
    "                        'f6b605f3b5dde0b21055694319853086',\n",
    "                        '433b60584fafba1ea3de07443b74cfd3'\n",
    "                        '2ce004a012020b07ef69e22ba8669333'),\n",
    "    'efficientnet-b3': ('03f1fba367f070bd2545f081cfa7f3e7'\n",
    "                        '6f5e1aa3b6f4db700f00552901e75ab9',\n",
    "                        'c5d42eb6cfae8567b418ad3845cfd63a'\n",
    "                        'a48b87f1bd5df8658a49375a9f3135c7'),\n",
    "    'efficientnet-b4': ('98852de93f74d9833c8640474b2c698d'\n",
    "                        'b45ec60690c75b3bacb1845e907bf94f',\n",
    "                        '7942c1407ff1feb34113995864970cd4'\n",
    "                        'd9d91ea64877e8d9c38b6c1e0767c411'),\n",
    "    'efficientnet-b5': ('30172f1d45f9b8a41352d4219bf930ee'\n",
    "                        '3339025fd26ab314a817ba8918fefc7d',\n",
    "                        '9d197bc2bfe29165c10a2af8c2ebc675'\n",
    "                        '07f5d70456f09e584c71b822941b1952'),\n",
    "    'efficientnet-b6': ('f5270466747753485a082092ac9939ca'\n",
    "                        'a546eb3f09edca6d6fff842cad938720',\n",
    "                        '1d0923bb038f2f8060faaf0a0449db4b'\n",
    "                        '96549a881747b7c7678724ac79f427ed'),\n",
    "    'efficientnet-b7': ('876a41319980638fa597acbbf956a82d'\n",
    "                        '10819531ff2dcb1a52277f10c7aefa1a',\n",
    "                        '60b56ff3a8daccc8d96edfd40b204c11'\n",
    "                        '3e51748da657afd58034d54d3cec2bac')\n",
    "}\n",
    "\n",
    "NS_WEIGHTS_PATH = 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/'\n",
    "NS_WEIGHTS_HASHES = {\n",
    "    'efficientnet-b0': ('5e376ca93bc6ba60f5245d13d44e4323', 'a5b48ae7547fc990c7e4f3951230290d'),\n",
    "    'efficientnet-b1': ('79d29151fdaec95ac78e1ca97fc09634', '4d35baa41ca36f175506a33918f7e334'),\n",
    "    'efficientnet-b2': ('8c643222ffb73a2bfdbdf90f2cde01af', 'e496e531f41242598288ff3a4b4199f9'),\n",
    "    'efficientnet-b3': ('3b29e32602dad75d1f575d9ded00f930', '47da5b154de1372b557a65795d3e6135'),\n",
    "    'efficientnet-b4': ('c000bfa03bf3c93557851b4e1fe18f51', '47c10902a4949eec589ab92fe1c35ed8'),\n",
    "    'efficientnet-b5': ('8a920cd4ee793f53c251a1ecd3a5cee6', '4d53ef3544d4114e2d8080d6d777a74c'),\n",
    "    'efficientnet-b6': ('cc69df409516ab57e30e51016326853e', '71f96d7e15d9f891f3729b4f4e701f77'),\n",
    "    'efficientnet-b7': ('1ac825752cbc26901c8952e030ae4dd9', 'e112b00c464fe929b821edbb35d1af55')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-wLVFNpArYfz"
   },
   "outputs": [],
   "source": [
    "_KERAS_BACKEND = None\n",
    "_KERAS_LAYERS = None\n",
    "_KERAS_MODELS = None\n",
    "_KERAS_UTILS = None\n",
    "\n",
    "def get_submodules_from_kwargs(kwargs):\n",
    "    #backend = kwargs.get('backend', _KERAS_BACKEND)\n",
    "    backend=keras.backend\n",
    "    #layers = kwargs.get('layers', _KERAS_LAYERS)\n",
    "    layers = keras.layers\n",
    "    #models = kwargs.get('models', _KERAS_MODELS)\n",
    "    models = tf.keras.models\n",
    "    utils = kwargs.get('utils', _KERAS_UTILS)\n",
    "    for key in kwargs.keys():\n",
    "        if key not in ['backend', 'layers', 'models', 'utils']:\n",
    "            raise TypeError('Invalid keyword argument: %s', key)\n",
    "    return backend, layers, models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "arCv38HOrYf0"
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors, Pavel Yakubovskiy, Björn Barz. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Contains definitions for EfficientNet model.\n",
    "[1] Mingxing Tan, Quoc V. Le\n",
    "  EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n",
    "  ICML'19, https://arxiv.org/abs/1905.11946\n",
    "\"\"\"\n",
    "\n",
    "# Code of this model implementation is mostly written by\n",
    "# Björn Barz ([@Callidior](https://github.com/Callidior))\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from six.moves import xrange\n",
    "#from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "#from keras_applications.imagenet_utils import preprocess_input as _preprocess_input\n",
    "\n",
    "#from . import get_submodules_from_kwargs\n",
    "#from .weights import IMAGENET_WEIGHTS_PATH, IMAGENET_WEIGHTS_HASHES, NS_WEIGHTS_HASHES, NS_WEIGHTS_PATH\n",
    "\n",
    "backend = None\n",
    "layers = None\n",
    "models = None\n",
    "keras_utils = None\n",
    "\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'strides', 'se_ratio'\n",
    "])\n",
    "# defaults will be a public argument for namedtuple in Python 3.7\n",
    "# https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "\n",
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n",
    "              expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25)\n",
    "]\n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1. / 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'uniform'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_input(x, **kwargs):\n",
    "    kwargs = {k: v for k, v in kwargs.items() if k in ['backend', 'layers', 'models', 'utils']}\n",
    "    return _preprocess_input(x, mode='torch', **kwargs)\n",
    "\n",
    "\n",
    "def get_swish(**kwargs):\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    def swish(x):\n",
    "        \"\"\"Swish activation function: x * sigmoid(x).\n",
    "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "        \"\"\"\n",
    "\n",
    "        if backend.backend() == 'tensorflow':\n",
    "            try:\n",
    "                # The native TF implementation has a more\n",
    "                # memory-efficient gradient implementation\n",
    "                return backend.tf.nn.swish(x)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "        return x * backend.sigmoid(x)\n",
    "\n",
    "    return swish\n",
    "\n",
    "\n",
    "def get_dropout(**kwargs):\n",
    "    \"\"\"Wrapper over custom dropout. Fix problem of ``None`` shape for tf.keras.\n",
    "    It is not possible to define FixedDropout class as global object,\n",
    "    because we do not have modules for inheritance at first time.\n",
    "    Issue:\n",
    "        https://github.com/tensorflow/tensorflow/issues/30946\n",
    "    \"\"\"\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    class FixedDropout(layers.Dropout):\n",
    "        def _get_noise_shape(self, inputs):\n",
    "            if self.noise_shape is None:\n",
    "                return self.noise_shape\n",
    "\n",
    "            symbolic_shape = backend.shape(inputs)\n",
    "            noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                           for axis, shape in enumerate(self.noise_shape)]\n",
    "            return tuple(noise_shape)\n",
    "\n",
    "    #return FixedDropout\n",
    "    return Dropout\n",
    "\n",
    "\n",
    "def round_filters(filters, width_coefficient, depth_divisor):\n",
    "    \"\"\"Round number of filters based on width multiplier.\"\"\"\n",
    "\n",
    "    filters *= width_coefficient\n",
    "    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
    "    new_filters = max(depth_divisor, new_filters)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_filters < 0.9 * filters:\n",
    "        new_filters += depth_divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "def round_repeats(repeats, depth_coefficient):\n",
    "    \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "\n",
    "    return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "\n",
    "def mb_conv_block(inputs, block_args, activation, drop_rate=None, prefix='', ):\n",
    "    \"\"\"Mobile Inverted Residual Bottleneck.\"\"\"\n",
    "\n",
    "    has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    # workaround over non working dropout with None in noise_shape in tf.keras\n",
    "    Dropout = get_dropout(\n",
    "        backend=backend,\n",
    "        layers=layers,\n",
    "        models=models,\n",
    "        utils=keras_utils\n",
    "    )\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = block_args.input_filters * block_args.expand_ratio\n",
    "    if block_args.expand_ratio != 1:\n",
    "        x = layers.Conv2D(filters, 1,\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                          name=prefix + 'expand_conv')(inputs)\n",
    "        x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'expand_bn')(x)\n",
    "        x = layers.Activation(activation, name=prefix + 'expand_activation')(x)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    x = layers.DepthwiseConv2D(block_args.kernel_size,\n",
    "                               strides=block_args.strides,\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=prefix + 'dwconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'bn')(x)\n",
    "    x = layers.Activation(activation, name=prefix + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if has_se:\n",
    "        num_reduced_filters = max(1, int(\n",
    "            block_args.input_filters * block_args.se_ratio\n",
    "        ))\n",
    "        se_tensor = layers.GlobalAveragePooling2D(name=prefix + 'se_squeeze')(x)\n",
    "\n",
    "        target_shape = (1, 1, filters) if backend.image_data_format() == 'channels_last' else (filters, 1, 1)\n",
    "        se_tensor = layers.Reshape(target_shape, name=prefix + 'se_reshape')(se_tensor)\n",
    "        se_tensor = layers.Conv2D(num_reduced_filters, 1,\n",
    "                                  activation=activation,\n",
    "                                  padding='same',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                                  name=prefix + 'se_reduce')(se_tensor)\n",
    "        se_tensor = layers.Conv2D(filters, 1,\n",
    "                                  activation='sigmoid',\n",
    "                                  padding='same',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                                  name=prefix + 'se_expand')(se_tensor)\n",
    "        if backend.backend() == 'theano':\n",
    "            # For the Theano backend, we have to explicitly make\n",
    "            # the excitation weights broadcastable.\n",
    "            pattern = ([True, True, True, False] if backend.image_data_format() == 'channels_last'\n",
    "                       else [True, False, True, True])\n",
    "            se_tensor = layers.Lambda(\n",
    "                lambda x: backend.pattern_broadcast(x, pattern),\n",
    "                name=prefix + 'se_broadcast')(se_tensor)\n",
    "        x = layers.multiply([x, se_tensor], name=prefix + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    x = layers.Conv2D(block_args.output_filters, 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=prefix + 'project_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'project_bn')(x)\n",
    "    if block_args.id_skip and all(\n",
    "            s == 1 for s in block_args.strides\n",
    "    ) and block_args.input_filters == block_args.output_filters:\n",
    "        if drop_rate and (drop_rate > 0):\n",
    "            x = Dropout(drop_rate,\n",
    "                        noise_shape=(None, 1, 1, 1),\n",
    "                        name=prefix + 'drop')(x)\n",
    "        x = layers.add([x, inputs], name=prefix + 'add')\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def EfficientNet(width_coefficient,\n",
    "                 depth_coefficient,\n",
    "                 default_resolution,\n",
    "                 dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2,\n",
    "                 depth_divisor=8,\n",
    "                 blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "                 model_name='efficientnet',\n",
    "                 include_top=True,\n",
    "                 weights='imagenet',\n",
    "                 input_tensor=None,\n",
    "                 input_shape=None,\n",
    "                 pooling=None,\n",
    "                 classes=1000,\n",
    "                 **kwargs):\n",
    "    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        width_coefficient: float, scaling coefficient for network width.\n",
    "        depth_coefficient: float, scaling coefficient for network depth.\n",
    "        default_resolution: int, default input image size.\n",
    "        dropout_rate: float, dropout rate before final classifier layer.\n",
    "        drop_connect_rate: float, dropout rate at skip connections.\n",
    "        depth_divisor: int.\n",
    "        blocks_args: A list of BlockArgs to construct block modules.\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False.\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    global backend, layers, models, keras_utils\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if not (weights in {'imagenet', 'noisy-student', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=default_resolution,\n",
    "                                      min_size=32,\n",
    "                                      data_format=backend.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if backend.backend() == 'tensorflow':\n",
    "            from tensorflow.python.keras.backend import is_keras_tensor\n",
    "        else:\n",
    "            is_keras_tensor = backend.is_keras_tensor\n",
    "        if not is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    #activation = get_swish(**kwargs)\n",
    "    activation = \"relu\"\n",
    "\n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.Conv2D(round_filters(32, width_coefficient, depth_divisor), 3,\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name='stem_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)\n",
    "    x = layers.Activation(activation, name='stem_activation')(x)\n",
    "\n",
    "    # Build blocks\n",
    "    num_blocks_total = sum(block_args.num_repeat for block_args in blocks_args)\n",
    "    block_num = 0\n",
    "    for idx, block_args in enumerate(blocks_args):\n",
    "        assert block_args.num_repeat > 0\n",
    "        # Update block input and output filters based on depth multiplier.\n",
    "        block_args = block_args._replace(\n",
    "            input_filters=round_filters(block_args.input_filters,\n",
    "                                        width_coefficient, depth_divisor),\n",
    "            output_filters=round_filters(block_args.output_filters,\n",
    "                                         width_coefficient, depth_divisor),\n",
    "            num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n",
    "\n",
    "        # The first block needs to take care of stride and filter size increase.\n",
    "        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "        x = mb_conv_block(x, block_args,\n",
    "                          activation=activation,\n",
    "                          drop_rate=drop_rate,\n",
    "                          prefix='block{}a_'.format(idx + 1))\n",
    "        block_num += 1\n",
    "        if block_args.num_repeat > 1:\n",
    "            # pylint: disable=protected-access\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=block_args.output_filters, strides=[1, 1])\n",
    "            # pylint: enable=protected-access\n",
    "            for bidx in xrange(block_args.num_repeat - 1):\n",
    "                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "                block_prefix = 'block{}{}_'.format(\n",
    "                    idx + 1,\n",
    "                    string.ascii_lowercase[bidx + 1]\n",
    "                )\n",
    "                x = mb_conv_block(x, block_args,\n",
    "                                  activation=activation,\n",
    "                                  drop_rate=drop_rate,\n",
    "                                  prefix=block_prefix)\n",
    "                block_num += 1\n",
    "\n",
    "    # Build top\n",
    "    x = layers.Conv2D(round_filters(1280, width_coefficient, depth_divisor), 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name='top_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)\n",
    "    x = layers.Activation(activation, name='top_activation')(x)\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        if dropout_rate and dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate, name='top_dropout')(x)\n",
    "        x = layers.Dense(classes,\n",
    "                         activation='softmax',\n",
    "                         kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "                         name='probs')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "\n",
    "        if include_top:\n",
    "            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_autoaugment.h5'\n",
    "            file_hash = IMAGENET_WEIGHTS_HASHES[model_name][0]\n",
    "        else:\n",
    "            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "            file_hash = IMAGENET_WEIGHTS_HASHES[model_name][1]\n",
    "        weights_path = keras_utils.get_file(\n",
    "            file_name,\n",
    "            IMAGENET_WEIGHTS_PATH + file_name,\n",
    "            cache_subdir='models',\n",
    "            file_hash=file_hash,\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    elif weights == 'noisy-student':\n",
    "\n",
    "        if include_top:\n",
    "            file_name = \"{}_{}.h5\".format(model_name, weights)\n",
    "            file_hash = NS_WEIGHTS_HASHES[model_name][0]\n",
    "        else:\n",
    "            file_name = \"{}_{}_notop.h5\".format(model_name, weights)\n",
    "            file_hash = NS_WEIGHTS_HASHES[model_name][1]\n",
    "        weights_path = keras_utils.get_file(\n",
    "            file_name,\n",
    "            NS_WEIGHTS_PATH + file_name,\n",
    "            cache_subdir='models',\n",
    "            file_hash=file_hash,\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def EfficientNetB0(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0, 1.0, 224, 0.2,\n",
    "        model_name='efficientnet-b0',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB1(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0, 1.1, 240, 0.2,\n",
    "        model_name='efficientnet-b1',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB2(include_top=True,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=1000,\n",
    "                   **kwargs):\n",
    "    return EfficientNet(\n",
    "        1.1, 1.2, 260, 0.3,\n",
    "        model_name='efficientnet-b2',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB3(include_top=True,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=1000,\n",
    "                   **kwargs):\n",
    "    return EfficientNet(\n",
    "        1.2, 1.4, 300, 0.3,\n",
    "        model_name='efficientnet-b3',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB4(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.4, 1.8, 380, 0.4,\n",
    "        model_name='efficientnet-b4',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB5(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.6, 2.2, 456, 0.4,\n",
    "        model_name='efficientnet-b5',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB6(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.8, 2.6, 528, 0.5,\n",
    "        model_name='efficientnet-b6',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB7(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        2.0, 3.1, 600, 0.5,\n",
    "        model_name='efficientnet-b7',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetL2(\n",
    "        include_top=True,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        4.3, 5.3, 800, 0.5,\n",
    "        model_name='efficientnet-l2',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "setattr(EfficientNetB0, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB1, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB2, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB3, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB4, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB5, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB6, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB7, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetL2, '__doc__', EfficientNet.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIq03pXhrYf0"
   },
   "source": [
    "## Configurando EfficientNet para obtener capa tipo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Gws-LMUCrYf0"
   },
   "outputs": [],
   "source": [
    "def inject_tfkeras_modules(func):\n",
    "    import tensorflow.keras as tfkeras\n",
    "    #@functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        kwargs['backend'] = tfkeras.backend\n",
    "        kwargs['layers'] = tfkeras.layers\n",
    "        kwargs['models'] = tfkeras.models\n",
    "        kwargs['utils'] = tfkeras.utils\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "6kt9sD4jrYf0"
   },
   "outputs": [],
   "source": [
    "EfficientNetB0 = inject_tfkeras_modules(EfficientNetB0)\n",
    "EfficientNetB1 = inject_tfkeras_modules(EfficientNetB1)\n",
    "EfficientNetB2 = inject_tfkeras_modules(EfficientNetB2)\n",
    "EfficientNetB3 = inject_tfkeras_modules(EfficientNetB3)\n",
    "EfficientNetB4 = inject_tfkeras_modules(EfficientNetB4)\n",
    "EfficientNetB5 = inject_tfkeras_modules(EfficientNetB5)\n",
    "EfficientNetB6 = inject_tfkeras_modules(EfficientNetB6)\n",
    "EfficientNetB7 = inject_tfkeras_modules(EfficientNetB7)\n",
    "EfficientNetL2 = inject_tfkeras_modules(EfficientNetL2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS_zAY6trYf0"
   },
   "source": [
    "## Arquitectura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HNA3ZDIrrYf0"
   },
   "outputs": [],
   "source": [
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "idyljVljrYf0"
   },
   "outputs": [],
   "source": [
    "# Creando el modelo EfficientNet con pesos preentrenados en ImageNet\n",
    "#rnet = efn.EfficientNetB7(weights=None, include_top=False, input_shape=[128,128,3])\n",
    "#rnet = tf.keras.applications.EfficientNetB7(weights=None, include_top=False, input_shape=[128,128,3]) # Tensoorflow 2.3.0 en adelante\n",
    "rnet = EfficientNetB7(weights=None, include_top=False, input_shape=[128,128,3])\n",
    "rnet = tf.keras.Sequential(rnet)\n",
    "rnet.add(Dropout(rate=dropout))\n",
    "rnet.add(Flatten())\n",
    "rnet.add(Dense(4096, activation='relu'))\n",
    "rnet.add(Dropout(rate=dropout))\n",
    "rnet.add(Dense(4096, activation='relu'))\n",
    "rnet.add(Dropout(rate=dropout))\n",
    "rnet.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp3NkqMrrYf0",
    "outputId": "b6cbf4ac-df63-431f-cb85-95456dd62bd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.functional.Functional at 0x7f8dc8dfd9e8>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f8dc85c6518>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x7f8dc84eb5f8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f8dc84eb8d0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f8dc71add68>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f8dc71bb358>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f8dc71bb208>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f8dc71c96a0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnet.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxNCKUiNrYf0",
    "outputId": "0e4dc777-c6a8-4eab-8874-ca7b538800e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b7 (Functional) (None, 4, 4, 2560)        64097680  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 2560)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40960)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              167776256 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 248,659,345\n",
      "Trainable params: 248,348,625\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQCJtWmlrYf0",
    "outputId": "fee2ee35-7e32-46b2-ce2d-ee484238e522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "SGQRhgzWrYf1"
   },
   "outputs": [],
   "source": [
    "rnet.load_weights('EFNB7_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1SAA9Pb1NcR"
   },
   "source": [
    "# Realizando Petición (Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nnQeWzP-1NcS"
   },
   "outputs": [],
   "source": [
    "# Definimos el arreglo que enviaremos para realizar la petición al modelo alojado en IBM WATOSN CLOUD\n",
    "score_0 = X_prueba_128.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "LucrddYs1NcS"
   },
   "outputs": [],
   "source": [
    "# Importando bibliotecas necesarias para realizar petcición\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "gO533pFu1NcS"
   },
   "outputs": [],
   "source": [
    "# Estableciendo datos de la aplicación WEB en IBM WATSON CLOUD\n",
    "# Y generando un token temporal para cceder a la aplicación\n",
    "API_KEY = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "token_response = requests.post('https://iam.ng.bluemix.net/identity/token', data={\"apikey\": API_KEY, \"grant_type\": 'urn:ibm:params:oauth:grant-type:apikey'})\n",
    "mltoken = token_response.json()[\"access_token\"]\n",
    "\n",
    "header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ikrX_O6y1NcS"
   },
   "outputs": [],
   "source": [
    "# Definimos el diccionario para la petición\n",
    "scoring_payload = {\"input_data\": [{\"values\": [score_0[0]]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbOb4OIf1NcS",
    "outputId": "941c0cb5-2ed1-4308-b0fd-e796e69be3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring response\n",
      "{'predictions': [{'fields': ['prediction', 'prediction_classes', 'probability'], 'id': 'dense_5', 'values': [[[0.021548636257648468], [0], [0.021548636257648468]]]}]}\n"
     ]
    }
   ],
   "source": [
    "response_scoring = requests.post('https://us-south.ml.cloud.ibm.com/ml/v4/deployments/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/predictions?version=2020-12-04', json=scoring_payload, headers={'Authorization': 'Bearer ' + mltoken})\n",
    "print(\"Scoring response\")\n",
    "print(response_scoring.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAahFgul1NcU"
   },
   "source": [
    "# Imprimiendo la probabilidad de cáncer mamario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_-IVrXv1NcU",
    "outputId": "277758ae-7027-46ad-be05-5ab809dff59f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021548636257648468"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo en IBM WATSON CLOUD\n",
    "response_scoring.json()['predictions'][0]['values'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJlWFMkM1NcU",
    "outputId": "1c563619-7ea8-4675-edd2-435f8d704c87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021548629"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo \"local\"\n",
    "rnet.predict(score_0)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6jFg1WX1NcV"
   },
   "source": [
    "**NOTAS:** la probabilidad mostrada es un valor entre 0 y 1.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Anexo_T.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
